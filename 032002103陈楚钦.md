

 - （1.1)在Github仓库中新建一个学号为名的文件夹，同时在博客正文首行给出作业Github链接，并登录 软工在线平台完善信息。（2'）
https://github.com/charlesccq/032002103-
## 一、PSP表格

PSP2.1 | Personal Software Process Stages	 | 预估时（分钟）|	实际时分钟）
-------- | ------------- | ------------- | -----
Planning	|计划		 |60|60
· Estimate	|· 估计这个任务需要多少时间	|1940|2060
Development	|开发		|300|300
· Analysis	|· 需求分析 (包括学习新技术)|600|720		
· Design Spec	|· 生成设计文档		|60|60
· Design Review	|· 设计复审		|30|30
· Coding Standard	|· 代码规范 (为目前的开发制定合适的规范)|60|60		
· Design	|· 具体设计		|300|300
· Coding	|· 具体编码		|300|300
· Code Review	|· 代码复审		|60|60
· Test	|· 测试（自我测试，修改代码，提交修改）|60|60		
Reporting	|报告		|60|60
· Test Repor	|· 测试报告		|60|60
· Size Measurement	|· 计算工作量|30|30		
· Postmortem & Process Improvement Plan	|· 事后总结, 并提出过程改进计划|60|60		
| |合计|1940|2060

## 二、任务要求的实现
 

 - 项目设计与技术栈。从阅读完题目到完成作业，这一次的任务被你拆分成了几个环节？你分别通过什么渠道、使用什么方式方法完成了各个环节？列出你完成本次任务所使用的技术栈。
    本次任务被我分成四个环节。
     第一个环节是如何避免卫健委官网的反爬机制 ，通过网上学习到的 pyppeteer，也就是进阶版的selenium，功能更完善，效率更高，更容易绕过反爬检测。但还是有一些超时问题不知如何解决
     第二个环节是获取疫情信息。
     第三个环节是对获取到的疫情信息进行分析。
     第四个环节是数据的可视化。
     用到的技术栈有：python，pyecharts，pycharm，VS code，Markdown，HTML等等
     
 - 爬虫与数据处理。说明业务逻辑，简述代码的设计过程（例如可介绍有几个类，几个函数，他们之间的关系），并对关键的函数或算法进行说明。
     1.第一个是将 pyppeteer 的操作封装成 fetchUrl 函数，用于发起网络请求，获取网页源码。
     2.根据 URL 构成规则，通过 getPageUrl 函数构造每一页的 URL 链接，可以根据注释来调整抓取的页数（range（1，n））。
     3. getTitleUrl 函数，页面每一篇文章的标题，链接，和发布日期。
     4.  getContent 函数，获取文章的正文内容，用于之后的数据分析。
     5. wb = xw.Book()，用于将数据封装进入Excel表格。
     6. 接下来就是主函数。建立好Excel表格来存储数据，接着用正则分析文本抓取所需获得的数据，将其一一存储到Excel表格之中。
    

 - 数据统计接口部分的性能改进。记录在数据统计接口的性能上所花费的时间，描述你改进的思路，并展示一张性能分析图（例如可通过VS2019/JProfiler的性能分析工具自动生成），并展示你程序中消耗最大的函数。
使用pycharm自带的性能分析工具。
![image](https://github.com/charlesccq/032002103-/blob/main/QQ%E6%88%AA%E5%9B%BE20220920152647.png)

 - 每日热点的实现思路。简要介绍实现该功能的算法原理，可给出必要的步骤流程图、数学公式推导和核心代码实现，并简要谈谈所采用算法的优缺点与可能的改进方案。
    我不会做，想不明白，还在努力
 - 数据可视化界面的展示。在博客中介绍数据可视化界面的组件和设计的思路。
![image](https://github.com/charlesccq/032002103-/blob/main/QQ%E6%88%AA%E5%9B%BE20220920171321.png)
x轴为地区名，y轴为本土新增病例和本土无症状新增
通过xlrd分析Excel数据，pyecharts构成柱状图
## 三、心得体会

 - 在这儿写下你完成本次作业的心得体会，当然，如果你还有想表达的东西但在上面两个板块没有体现，也可以写在这儿~
本次任务对我而言，真的很难，几乎所有都是些新学的，以前没有接触过python，这次任务只能靠自学，还有爬虫的问题，也是从网上查找学习的，但依然也有很多不明白的地方。代码还有挺多报错的地方，一些超时问题之类的，格式可能也不够规范，虽然很辛苦，但是也学习到了很多，比如爬虫的引用啊，一些像是requests等等的使用，还有可视化化的柱状图，不是很完善就是了，地图有尝试去做，，但是做不来。还是有挺多不懂的就是了。说到底，这次任务也算是一次不错的尝试了，收获很大，继续加油！
